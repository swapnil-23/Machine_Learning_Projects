{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport random\nimport datetime\nimport matplotlib.pyplot as plt\nfrom shapely.wkt import loads as wkt_loads\nimport tifffile as tiff\n\nfrom keras import backend as K\n# from sklearn.metrics import jaccard_similarity_score\nfrom shapely.geometry import MultiPolygon, Polygon\nfrom shapely.wkt import loads\nimport shapely.wkt ## for the manipulation of planar features\nimport shapely.affinity\nfrom collections import defaultdict\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\nimport gc\nimport warnings\nimport zipfile\nwarnings.filterwarnings(\"ignore\")\nfrom keras.models import load_model\nimport tensorflow as tf\nimport random as rn\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\nfrom tqdm import tqdm ## for the progress meter\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:49:53.233440Z","iopub.execute_input":"2022-06-30T18:49:53.233863Z","iopub.status.idle":"2022-06-30T18:50:00.140588Z","shell.execute_reply.started":"2022-06-30T18:49:53.233780Z","shell.execute_reply":"2022-06-30T18:50:00.139640Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/data')\nos.mkdir('/kaggle/msk')\nos.mkdir('/kaggle/model_weights')\nos.mkdir('/kaggle/subm')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:50:19.888374Z","iopub.execute_input":"2022-06-30T18:50:19.889298Z","iopub.status.idle":"2022-06-30T18:50:19.897678Z","shell.execute_reply.started":"2022-06-30T18:50:19.889258Z","shell.execute_reply":"2022-06-30T18:50:19.896723Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/x_tr_a')\nos.mkdir('/kaggle/x_tr_na')\nos.mkdir('/kaggle/y_tr_a')\nos.mkdir('/kaggle/y_tr_na')\n\nos.mkdir('/kaggle/x_val_a')\nos.mkdir('/kaggle/x_val_na')\nos.mkdir('/kaggle/y_val_a')\nos.mkdir('/kaggle/y_val_na')\n\nos.mkdir('/kaggle/x_test_a')\nos.mkdir('/kaggle/x_test_na')\nos.mkdir('/kaggle/y_test_a')\nos.mkdir('/kaggle/y_test_na')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:50:21.693019Z","iopub.execute_input":"2022-06-30T18:50:21.693613Z","iopub.status.idle":"2022-06-30T18:50:21.705996Z","shell.execute_reply.started":"2022-06-30T18:50:21.693578Z","shell.execute_reply":"2022-06-30T18:50:21.704854Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Performing EDA","metadata":{}},{"cell_type":"code","source":"## reading the wkt files\nwkt_df = pd.read_csv('../input/dstl-satellite-imagery-feature-detection/train_wkt_v4.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:50:53.607331Z","iopub.execute_input":"2022-06-30T18:50:53.607782Z","iopub.status.idle":"2022-06-30T18:50:54.766869Z","shell.execute_reply.started":"2022-06-30T18:50:53.607743Z","shell.execute_reply":"2022-06-30T18:50:54.765730Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Class Label**\n1. Buildings - large building, residential, non-residential, fuel storage facility, fortified building\n2. Misc. Manmade structures\n3. Road\n4. Track - poor/dirt/cart track, footpath/trail\n5. Trees - woodland, hedgerows, groups of trees, standalone trees\n6. Crops - contour ploughing/cropland, grain (wheat) crops, row (potatoes, turnips) crops\n7. Waterway\n8. Standing water\n9. Vehicle Large - large vehicle (e.g. lorry, truck,bus), logistics vehicle\n10. Vehicle Small - small vehicle (car, van), motorbike","metadata":{}},{"cell_type":"code","source":"#Unique Images\n\nlen(wkt_df['ImageId'].unique()) \n\n## there are 25 total unqiue image ids","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:51:07.721740Z","iopub.execute_input":"2022-06-30T18:51:07.722407Z","iopub.status.idle":"2022-06-30T18:51:07.740021Z","shell.execute_reply.started":"2022-06-30T18:51:07.722367Z","shell.execute_reply":"2022-06-30T18:51:07.738918Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"wkt_df[wkt_df['MultipolygonWKT']!='MULTIPOLYGON EMPTY']['ClassType'].value_counts()\\\n                      .plot.bar(title = 'frequency of class lable in images')\nplt.xlabel('class label')\nplt.ylabel('frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:51:13.258171Z","iopub.execute_input":"2022-06-30T18:51:13.258514Z","iopub.status.idle":"2022-06-30T18:51:13.644792Z","shell.execute_reply.started":"2022-06-30T18:51:13.258485Z","shell.execute_reply":"2022-06-30T18:51:13.643838Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 3-Band images\ndef stretch2(band, lower_percent=2, higher_percent=98):\n    a = 0 #np.min(band)\n    b = 255  #np.max(band)\n    c = np.percentile(band, lower_percent)\n    d = np.percentile(band, higher_percent)        \n    out = a + (band - c) * (b - a) / (d - c)    \n    out[out<a] = a\n    out[out>b] = b\n    return out\n\ndef adjust_contrast(x):    \n    for i in range(3):\n        x[:,:,i] = stretch2(x[:,:,i])\n    return x.astype(np.uint8) \n\n## reading the 3 band images\nglobal rgb\ndef display_img(ImageId):\n    zip_path = '../input/dstl-satellite-imagery-feature-detection/three_band.zip'\n    rgbfile = '{}_M.tif'.format(ImageId)\n    with zipfile.ZipFile(zip_path) as myzip:\n        files_in_zip = myzip.namelist()\n        for fname in files_in_zip:\n            if fname.endswith(rgbfile):\n                with myzip.open(fname) as myfile:\n                    rgb = tiff.imread(myfile)\n                    rgb = np.rollaxis(rgb, 0, 3)\n                    return rgb\n                x = adjust_contrast(rgb).copy()\n                ax[1].imshow(x,extent=[0, 0.0092, -0.009, 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:52:21.715821Z","iopub.execute_input":"2022-06-30T18:52:21.716825Z","iopub.status.idle":"2022-06-30T18:52:21.727274Z","shell.execute_reply.started":"2022-06-30T18:52:21.716781Z","shell.execute_reply":"2022-06-30T18:52:21.725936Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":" #storing one multipoligon in pol\npol = loads(wkt_df['MultipolygonWKT'][11])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:52:34.765363Z","iopub.execute_input":"2022-06-30T18:52:34.765789Z","iopub.status.idle":"2022-06-30T18:52:34.796394Z","shell.execute_reply.started":"2022-06-30T18:52:34.765731Z","shell.execute_reply":"2022-06-30T18:52:34.795441Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"wkt_df['Multipolygons'] = wkt_df.apply(lambda a: loads(a.MultipolygonWKT), axis=1)\nwkt_df['Num_Multipolygons'] = wkt_df.apply(lambda a: len(a['Multipolygons'].geoms), axis=1) \nobjects_per_image = wkt_df.pivot(index='ClassType', columns='ImageId', values='Num_Multipolygons')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:52:37.442967Z","iopub.execute_input":"2022-06-30T18:52:37.443938Z","iopub.status.idle":"2022-06-30T18:52:39.342800Z","shell.execute_reply.started":"2022-06-30T18:52:37.443889Z","shell.execute_reply":"2022-06-30T18:52:39.341888Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#plotting polygons for all the images\n\nc=0\nfor img_id in wkt_df['ImageId'].unique():\n    df = wkt_df[wkt_df['ImageId']==img_id]\n    fig, ax = plt.subplots(1, 2,figsize=(20, 10))  #increase figsize and run again\n    for ele1 in df['Multipolygons']:\n        for ele2 in ele1:\n            x,y = ele2.exterior.xy\n            ax[0].plot(x,y,'red')\n            ax[0].axis('off')\n    display_img(img_id)\n    #ax[0].title(f\"Image {wkt_df['ImageId'][i]}\")\n    ax[0].set_title(f\"Image {img_id}\")\n    ax[1].axis('off')\n    plt.show()\n    c += 1\n    if c==3:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:53:04.024734Z","iopub.execute_input":"2022-06-30T18:53:04.025572Z","iopub.status.idle":"2022-06-30T18:55:28.286803Z","shell.execute_reply.started":"2022-06-30T18:53:04.025538Z","shell.execute_reply":"2022-06-30T18:55:28.285828Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#class labels in dictionary as key and value pair\nclass_label = {\n    1:'Buildings',\n    2:'Misc. Manmade structures',\n    3:'Road',\n    4:'Track',\n    5:'Trees',\n    6:'Crops',\n    7:'Waterway',\n    8:'Standing water',\n    9:'Vehicle Large',\n    10:'Vehicle Small'\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:55:42.689293Z","iopub.execute_input":"2022-06-30T18:55:42.689853Z","iopub.status.idle":"2022-06-30T18:55:42.696190Z","shell.execute_reply.started":"2022-06-30T18:55:42.689809Z","shell.execute_reply":"2022-06-30T18:55:42.695058Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"Classes = {1: 'Building', 2: 'Structure', 3: 'Road', 4: 'Track', 5: 'Trees', 6: 'Crops', 7: 'Waterway', 8: 'Standing water', 9: 'Truck', 10: 'Car'}\nColors = {1:'#d73027' , 2: '#f46d43', 3: '#4575b4', 4:'#74add1' , 5: '#dfc27d', 6: '#a6dba0', 7: '#1b7837', 8: '#b35806', 9: '0.4',  10: '0.7'}","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:55:49.825087Z","iopub.execute_input":"2022-06-30T18:55:49.825453Z","iopub.status.idle":"2022-06-30T18:55:49.832994Z","shell.execute_reply.started":"2022-06-30T18:55:49.825413Z","shell.execute_reply":"2022-06-30T18:55:49.830432Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def image_stats(image_id):\n    '''\n    creating dataframe which contains \n    classes, number of polygon as counts and total area of image with id image_id\n    '''\n    counts, total_area = {}, {}\n    xmax = GS[GS.ImageId == image_id].Xmax.values[0]\n    ymin = GS[GS.ImageId == image_id].Ymin.values[0]\n    image_area = abs(xmax * ymin) #area of image\n    for cl in Classes:\n        all_poly = wkt_df[wkt_df.ImageId == image_id]\n        poly = all_poly[all_poly.ClassType == cl].MultipolygonWKT\n        poly_list = wkt_loads(poly.values[0])\n        counts[cl] = len(poly_list)  #number of polygons of classtype cl\n\n        if len(poly_list) > 0:\n            #calculating area of all polygon for class cl having number of polygons more than one\n            total_area[cl] = np.sum([poly.area for poly in poly_list])\\\n                             / image_area * 100 \n   \n    df = pd.DataFrame({'Class': Classes, 'Counts': counts,\n                         'TotalArea': total_area})\n    return df ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:56:08.265743Z","iopub.execute_input":"2022-06-30T18:56:08.266794Z","iopub.status.idle":"2022-06-30T18:56:08.278179Z","shell.execute_reply.started":"2022-06-30T18:56:08.266756Z","shell.execute_reply":"2022-06-30T18:56:08.277163Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"##printing the the grid sizes of the images\nGS = pd.read_csv('../input/dstl-satellite-imagery-feature-detection/grid_sizes.csv.zip')\nGS = GS.rename(columns={'Unnamed: 0':'ImageId'})\nprint(GS)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:56:41.186329Z","iopub.execute_input":"2022-06-30T18:56:41.187237Z","iopub.status.idle":"2022-06-30T18:56:41.210560Z","shell.execute_reply.started":"2022-06-30T18:56:41.187188Z","shell.execute_reply":"2022-06-30T18:56:41.209570Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"stats_list = []\nImages = sorted(set(wkt_df['ImageId']))\nfor image_no, image_id in enumerate(Images):\n    stat = image_stats(image_id)\n    stat['ImageId'] = image_id\n    stats_list.append(stat)\n        \nstats = pd.concat(stats_list)\npvt_stats = stats.pivot(index = 'Class', columns = 'ImageId', values = 'TotalArea')\npercent_area = np.cumsum(pvt_stats, axis = 0)\n\nclass_r = {}\nfor cl in Classes:\n    class_r[Classes[cl]] = cl","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:56:58.052223Z","iopub.execute_input":"2022-06-30T18:56:58.052574Z","iopub.status.idle":"2022-06-30T18:57:01.494306Z","shell.execute_reply.started":"2022-06-30T18:56:58.052544Z","shell.execute_reply":"2022-06-30T18:57:01.493151Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#iterating through all class to plot bar plot\nimport seaborn as sns\nfor cl in np.arange(1, 11):\n    class_name = percent_area.index[-cl]\n    class_id = class_r[class_name]\n    ax = sns.barplot(x = percent_area.columns, y = percent_area.loc[class_name],\n                         color = Colors[class_id], label = class_name)\n\nsns.set_context({'figure.figsize': (15, 8)})\nax.legend(loc = 2)\nsns.set_style(\"dark\")\nax.set_xticklabels(percent_area.columns, rotation = 45)\n\nax.set_xlabel('Image ID')\nax.set_ylabel('Total Area')\nplt.title('Areas of the objects in Image')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:57:22.188753Z","iopub.execute_input":"2022-06-30T18:57:22.189782Z","iopub.status.idle":"2022-06-30T18:57:23.584760Z","shell.execute_reply.started":"2022-06-30T18:57:22.189729Z","shell.execute_reply":"2022-06-30T18:57:23.583835Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"From the above graph we can see that \n1. Trees have highest area covered\n2. After trees crops have highest area covered\n3. Water and vehicles cover the less area","metadata":{}},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"## we are having 10 classes\nnum_cls = 10\n\nsize = 160\n\n#reduces and suppresses image noises\nsmooth = 1e-12\ninDir = '../input/dstl-satellite-imagery-feature-detection'\nTR = pd.read_csv(inDir + '/train_wkt_v4.csv.zip')\nGS = pd.read_csv(inDir + '/grid_sizes.csv.zip', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n\n#SF = pd.read_csv('/content/sample_submission.csv')\nGS = GS.rename( columns={'Unnamed: 0':'ImageId'}) #rename 'ImageId'","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:57:31.939164Z","iopub.execute_input":"2022-06-30T18:57:31.939761Z","iopub.status.idle":"2022-06-30T18:57:32.774227Z","shell.execute_reply.started":"2022-06-30T18:57:31.939717Z","shell.execute_reply":"2022-06-30T18:57:32.773238Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## Adjusting the contrast of the image bands\n\ndef adjust_contrast(bands, lower_percent=2, higher_percent=98):\n    \n    out = np.zeros_like(bands).astype(np.float32)\n    n = bands.shape[2]\n    for i in range(n):\n        a = 0  # min(band)\n        b = 1  # max(band)\n        c = np.percentile(bands[:, :, i], lower_percent)\n        d = np.percentile(bands[:, :, i], higher_percent)\n        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n        t[t < a] = a\n        t[t > b] = b\n        out[:, :, i] = t\n\n    return out.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:58:46.807483Z","iopub.execute_input":"2022-06-30T18:58:46.807967Z","iopub.status.idle":"2022-06-30T18:58:46.819859Z","shell.execute_reply.started":"2022-06-30T18:58:46.807918Z","shell.execute_reply":"2022-06-30T18:58:46.818183Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## converting the coordinates into raster(pixels)\ndef coordi_to_raster(coords, img_size, xmax, ymax):\n    \n    H, W = img_size\n    W1 = 1.0 * W * W / (W + 1)\n    H1 = 1.0 * H * H / (H + 1)\n    xf = W1 / xmax\n    yf = H1 / ymax\n    coords[:, 1] *= yf\n    coords[:, 0] *= xf\n    coords_int = np.round(coords).astype(np.int32)\n    return coords_int","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:58:51.333798Z","iopub.execute_input":"2022-06-30T18:58:51.334267Z","iopub.status.idle":"2022-06-30T18:58:51.341385Z","shell.execute_reply.started":"2022-06-30T18:58:51.334230Z","shell.execute_reply":"2022-06-30T18:58:51.340187Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"## creating the image masks with mutliploygon objects using exterior and interior coordinates of the given multiploygon\ndef convert_contours(polygonList, raster_img_size, xmax, ymax):\n    \n    perim_list = []\n    interior_list = []\n    if polygonList is None:\n        return None\n    for k in range(len(polygonList)):\n        poly = polygonList[k]\n        perim = np.array(list(poly.exterior.coords))\n        perim_c = coordi_to_raster(perim, raster_img_size, xmax, ymax)\n        perim_list.append(perim_c)\n        for pi in poly.interiors:\n            interior = np.array(list(pi.coords))\n            interior_c = coordi_to_raster(interior, raster_img_size, xmax, ymax)\n            interior_list.append(interior_c)\n    return perim_list, interior_list\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:58:54.413497Z","iopub.execute_input":"2022-06-30T18:58:54.413908Z","iopub.status.idle":"2022-06-30T18:58:54.421595Z","shell.execute_reply.started":"2022-06-30T18:58:54.413851Z","shell.execute_reply":"2022-06-30T18:58:54.420142Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# to generate the image masks using the image_size, image_id, class_type\n\ndef generate_mask_for_image_and_class(raster_size, image_id, class_type):\n\n    xmax, ymax = GS[GS.ImageId == image_id].iloc[0, 1:].astype(float)\n\n    df_image = TR[TR.ImageId == image_id]\n    multipoly_def = df_image[df_image.ClassType == class_type].MultipolygonWKT\n    polygonList = None\n    if len(multipoly_def) > 0:\n        assert len(multipoly_def) == 1\n        polygonList = wkt_loads(multipoly_def.values[0])\n    \n    contours = convert_contours(polygonList, raster_size, xmax, ymax)\n\n    img_mask = np.zeros(raster_size, np.uint8)\n    if contours is None:\n        return img_mask\n    perim_list, interior_list = contours\n    cv2.fillPoly(img_mask, perim_list, 1)\n    cv2.fillPoly(img_mask, interior_list, 0)\n\n    return img_mask","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:58:57.361501Z","iopub.execute_input":"2022-06-30T18:58:57.362393Z","iopub.status.idle":"2022-06-30T18:58:57.372061Z","shell.execute_reply.started":"2022-06-30T18:58:57.362347Z","shell.execute_reply":"2022-06-30T18:58:57.371066Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"## returns image pathces(crops) of given image and mask patch_size = 160*160 pixels\n    \ndef get_patches(img, msk, name1, name2, name3, name4, amt, aug=True):\n    random.seed(42)\n    is2 = int(1.0 * size)\n\n    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n\n    a, b , c, d = [], [], [], []\n\n    # thresholds for each class to get patches\n    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n    \n    xyz = np.ceil(amt*0.10).astype(int)\n    amt1 = amt-xyz\n    amt2 = xyz\n\n   # to get augmented data\n    for i in range(amt1):\n\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n     \n        for j in range(num_cls):\n            sm = np.sum(ms[:, :, j])\n\n            if 1.0 * sm / is2 ** 2 > tr[j]:\n               \n                #augmentation\n                if aug:\n                    \n                    # reversing\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[::-1]\n                        ms = ms[::-1]\n\n                    #flipping \n                    if random.uniform(0, 1) > 0.5:\n                        im = im[:, ::-1]\n                        ms = ms[:, ::-1]\n                    rotation = np.random.randint(4) # 0, 1, 2, 3\n\n                    #transpose & rotation\n                    if random.uniform(0, 1) > 0.5:\n                       im = np.rot90(im.transpose((1,0,2)), k=rotation)\n                       ms = np.rot90(ms.transpose((1,0,2)), k=rotation)\n                    \n                    #rotation\n                    if random.uniform(0, 1) > 0.5:\n                      im = np.rot90(im, k=rotation)\n                      ms = np.rot90(ms, k=rotation)\n                    \n                    #shearing \n                    if random.uniform(0, 1) > 0.5:\n                       im = tf.keras.preprocessing.image.apply_affine_transform(im, shear=0)\n                       im = tf.keras.preprocessing.image.apply_affine_transform(im, shear=0)\n                                     \n                \n                im = im.astype(np.float16)\n                ms = ms.astype(np.float16)\n                \n                \n                np.save(\"/kaggle/{}/{}\".format(name1, i),im)  \n                np.save(\"/kaggle/{}/{}\".format(name2, i),ms)  \n               \n                a.append(\"/kaggle/{}/{}.npy\".format(name1, i))\n                b.append(\"/kaggle/{}/{}.npy\".format(name2, i))\n\n    # to get non-augmented data\n    for i in range(amt2):\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n        im = im.astype(np.float16)\n        ms = ms.astype(np.float16)\n                                  \n        np.save(\"/kaggle/{}/{}\".format(name3, i),im)  \n        np.save(\"/kaggle/{}/{}\".format(name4, i),ms)  \n                \n        c.append(\"/kaggle/{}/{}.npy\".format(name3, i))\n        d.append(\"/kaggle/{}/{}.npy\".format(name4, i))\n\n    \n    print(len(a), len(b))\n    print(len(c), len(d))\n  \n    return a+c, b+d","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:59:02.735889Z","iopub.execute_input":"2022-06-30T18:59:02.736400Z","iopub.status.idle":"2022-06-30T18:59:02.758064Z","shell.execute_reply.started":"2022-06-30T18:59:02.736364Z","shell.execute_reply":"2022-06-30T18:59:02.756800Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class Dataloder(tf.keras.utils.Sequence):    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        \n        #print(len(batch))\n        return tuple(batch)\n    \n    def __len__(self):\n        return len(self.indexes) // self.batch_size\n\nclass Dataset:\n  \n    def __init__(self, images_dir, mask_dir):\n        \n        self.ids = images_dir\n        self.images_fps = images_dir\n        self.masks_fps  = mask_dir\n    \n    def __getitem__(self, i):\n        \n        # read data\n        image = np.load(self.images_fps[i]) \n        mask  = np.load(self.masks_fps[i])\n\n          \n        image = np.stack(image, axis=-1).astype('float')\n        mask = np.stack(mask, axis=-1).astype('float')\n\n        #image = np.transpose(image, (1,0,2)) \n        #mask = np.transpose(mask, (1,0,2)) \n    \n        image = np.transpose(image, (0,2,1)) \n        mask = np.transpose(mask, (0,2,1)) \n  \n        return image, mask\n      \n    def __len__(self):\n        return len(self.ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:59:06.761712Z","iopub.execute_input":"2022-06-30T18:59:06.762077Z","iopub.status.idle":"2022-06-30T18:59:06.775759Z","shell.execute_reply.started":"2022-06-30T18:59:06.762044Z","shell.execute_reply":"2022-06-30T18:59:06.774666Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"## rgb image detection using M band\ndef M(image_id):\n    zip_path = '../input/dstl-satellite-imagery-feature-detection/sixteen_band.zip'\n    tgtImg = '{}_M.tif'.format(image_id)\n    with zipfile.ZipFile(zip_path) as myzip:\n        files_in_zip = myzip.namelist()\n        for fname in files_in_zip:\n            if fname.endswith(tgtImg):\n                with myzip.open(fname) as myfile:\n                    img = tiff.imread(myfile)\n                    img = np.rollaxis(img, 0, 3)\n                    return img\n                \n                \n\nprint (\"combining all the images\")\ns = 835\n\nX = np.zeros((5 * s, 5 * s, 8))\nY = np.zeros((5 * s, 5 * s, num_cls))  \n\nids = sorted(set(TR.ImageId))\nprint (len(ids))\n\nfor i in range(5):\n    for j in range(5):\n        id = ids[5 * i + j]\n\n        rgb_img = M(id)\n        img = adjust_contrast(rgb_img).copy()\n        \n        \n        print (img.shape, id)\n        X[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n        for z in range(num_cls):\n            Y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n                (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n\nnp.save('/kaggle/data/X', X)\nnp.save('/kaggle/data/Y', Y)\nprint(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:59:10.112439Z","iopub.execute_input":"2022-06-30T18:59:10.112787Z","iopub.status.idle":"2022-06-30T18:59:38.876680Z","shell.execute_reply.started":"2022-06-30T18:59:10.112756Z","shell.execute_reply":"2022-06-30T18:59:38.874917Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"**Splitting the dataset into training, validation and test dataset**","metadata":{}},{"cell_type":"code","source":"#img, msk, name1, name2, name3, name4, amt, aug=True\n#training the dataset\nx_train, y_train = get_patches(X, Y, 'x_tr_a', 'y_tr_a', 'x_tr_na', 'y_tr_na', 20000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:00:16.300748Z","iopub.execute_input":"2022-06-30T19:00:16.301698Z","iopub.status.idle":"2022-06-30T19:02:12.794780Z","shell.execute_reply.started":"2022-06-30T19:00:16.301660Z","shell.execute_reply":"2022-06-30T19:02:12.793577Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#validation dataset\nx_val, y_val = get_patches(X, Y, 'x_val_a', 'y_val_a', 'x_val_na', 'y_val_na', 4000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:02:25.915536Z","iopub.execute_input":"2022-06-30T19:02:25.915914Z","iopub.status.idle":"2022-06-30T19:02:48.572160Z","shell.execute_reply.started":"2022-06-30T19:02:25.915861Z","shell.execute_reply":"2022-06-30T19:02:48.571096Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#test dataset\nx_test, y_test = get_patches(X, Y, 'x_test_a', 'y_test_na', 'x_test_a', 'y_test_na', 4000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:02:58.264326Z","iopub.execute_input":"2022-06-30T19:02:58.265464Z","iopub.status.idle":"2022-06-30T19:03:21.623067Z","shell.execute_reply.started":"2022-06-30T19:02:58.265419Z","shell.execute_reply":"2022-06-30T19:03:21.621883Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(x_train, y_train)\ntrain_dataloader = Dataloder(train_dataset, batch_size=8)\nval_dataset = Dataset(x_val, y_val)\nval_dataloader = Dataloder(val_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:03:29.622100Z","iopub.execute_input":"2022-06-30T19:03:29.622732Z","iopub.status.idle":"2022-06-30T19:03:29.628921Z","shell.execute_reply.started":"2022-06-30T19:03:29.622692Z","shell.execute_reply":"2022-06-30T19:03:29.627269Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dataloader[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:03:32.647955Z","iopub.execute_input":"2022-06-30T19:03:32.649022Z","iopub.status.idle":"2022-06-30T19:03:32.692042Z","shell.execute_reply.started":"2022-06-30T19:03:32.648969Z","shell.execute_reply":"2022-06-30T19:03:32.691153Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## calculating the jaccard coefficient\ndef jaccard_coef(y_true, y_pred):\n    \n    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n    total = K.sum(y_true + y_pred, axis=[0, -1, -2])\n    union = total - intersection\n\n    jac = (intersection + smooth) / (union+ smooth)\n\n    return K.mean(jac)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:03:34.858056Z","iopub.execute_input":"2022-06-30T19:03:34.858616Z","iopub.status.idle":"2022-06-30T19:03:34.864446Z","shell.execute_reply.started":"2022-06-30T19:03:34.858582Z","shell.execute_reply":"2022-06-30T19:03:34.863351Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"##fixing numpy RS\nnp.random.seed(42)\n\n##fixing tensorflow RS\ntf.random.set_seed(32)\n\n##python RS\nrn.seed(12)\n\n## making the U-NET model\ndef UNet():\n    \n    tf.random.set_seed(32)\n    classes= 10\n    img_input = Input(shape=(size, size, 8))\n    x = img_input\n\n    # Making the Encoder \n    \n    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 23))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',  kernel_initializer = tf.keras.initializers.he_normal(seed= 43))(x)\n   # x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 32))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 41))(x)\n   # x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 33))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n    x = Dropout(0.5)(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 35))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 54))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 39))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    #Making the Decoder\n    \n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 45))(x)\n   # x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 41))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 49))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n      \n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 18))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 21))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(classes, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 16))(x)\n    x = Dropout(0.25)(x)\n  \n    x = Activation(\"softmax\")(x)\n    \n    model = Model(img_input, x)\n  \n    model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=[jaccard_coef, 'accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:03:53.693220Z","iopub.execute_input":"2022-06-30T19:03:53.693597Z","iopub.status.idle":"2022-06-30T19:03:53.717230Z","shell.execute_reply.started":"2022-06-30T19:03:53.693564Z","shell.execute_reply":"2022-06-30T19:03:53.716198Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"##changing the learning rates\ndef changeLearningRate(epoch):\n\n    #lr=0.001\n    lr=0.0001\n    if epoch > 10 and epoch <=20:\n      lr*=0.1\n    elif epoch > 20 and epoch <=30:\n      lr*=0.01\n    elif epoch > 30 and epoch <=40:\n      lr*=0.001\n    elif epoch > 40 and epoch <=50:  \n      lr*=0.0001\n    elif epoch > 50 and epoch <=60:  \n      lr*=0.0001  \n    elif epoch > 60:\n      lr*=0.0001\n\n    return lr","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:03:58.796061Z","iopub.execute_input":"2022-06-30T19:03:58.796483Z","iopub.status.idle":"2022-06-30T19:03:58.810246Z","shell.execute_reply.started":"2022-06-30T19:03:58.796448Z","shell.execute_reply":"2022-06-30T19:03:58.808917Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"## to stop the nueral network using callback functions\n\nACCURACY_THRESHOLD=0.502\n\nclass myCallback(tf.keras.callbacks.Callback): \n    \n    def on_epoch_end(self, epoch, logs={}): \n        if (logs.get('val_jaccard_coef') > ACCURACY_THRESHOLD) and (logs.get('jaccard_coef') > ACCURACY_THRESHOLD):   \n          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n          self.model.stop_training = True\n\nstop = myCallback()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:01.538854Z","iopub.execute_input":"2022-06-30T19:04:01.539835Z","iopub.status.idle":"2022-06-30T19:04:01.546526Z","shell.execute_reply.started":"2022-06-30T19:04:01.539789Z","shell.execute_reply":"2022-06-30T19:04:01.545341Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"filepath=\"/kaggle/model_weights/weights-{epoch:02d}-{val_jaccard_coef:.4f}.hdf5\"\n\ncheckpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:04.943600Z","iopub.execute_input":"2022-06-30T19:04:04.944267Z","iopub.status.idle":"2022-06-30T19:04:04.949242Z","shell.execute_reply.started":"2022-06-30T19:04:04.944230Z","shell.execute_reply":"2022-06-30T19:04:04.948269Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"## to reduce the learning rate when the metric has stopped improving\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose = 1, min_delta = 0.0001)\nlrschedule = LearningRateScheduler(changeLearningRate, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:07.939882Z","iopub.execute_input":"2022-06-30T19:04:07.940413Z","iopub.status.idle":"2022-06-30T19:04:07.947071Z","shell.execute_reply.started":"2022-06-30T19:04:07.940379Z","shell.execute_reply":"2022-06-30T19:04:07.945371Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model = UNet()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:11.004705Z","iopub.execute_input":"2022-06-30T19:04:11.005393Z","iopub.status.idle":"2022-06-30T19:04:14.604394Z","shell.execute_reply.started":"2022-06-30T19:04:11.005334Z","shell.execute_reply":"2022-06-30T19:04:14.603489Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"## summary of the U-NET model\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:19.807784Z","iopub.execute_input":"2022-06-30T19:04:19.808889Z","iopub.status.idle":"2022-06-30T19:04:19.819290Z","shell.execute_reply.started":"2022-06-30T19:04:19.808828Z","shell.execute_reply":"2022-06-30T19:04:19.818205Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"## U-NET Plot summary\n\ntf.keras.utils.plot_model(model, \"model.png\", show_shapes=False, show_dtype=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:26.118355Z","iopub.execute_input":"2022-06-30T19:04:26.119085Z","iopub.status.idle":"2022-06-30T19:04:27.429232Z","shell.execute_reply.started":"2022-06-30T19:04:26.119048Z","shell.execute_reply":"2022-06-30T19:04:27.428089Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"##fitting the model\n\nmodel_fitting = model.fit_generator(train_dataloader, \n                              steps_per_epoch=len(train_dataloader),\n                              epochs=30,\n                              validation_data=val_dataloader,\n                              verbose=1,\n                              callbacks=checkpoint\n                              )","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:04:35.055660Z","iopub.execute_input":"2022-06-30T19:04:35.056060Z","iopub.status.idle":"2022-06-30T20:05:31.840445Z","shell.execute_reply.started":"2022-06-30T19:04:35.056019Z","shell.execute_reply":"2022-06-30T20:05:31.838099Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"**We can see that the accuracy achieved after running the U-NET model is 66.74%**","metadata":{}},{"cell_type":"code","source":"##plotting the training accuracy\nplt.figure(figsize=(15,5))\nplt.plot(range(model_fitting.epoch[-1]+1),model_fitting.history['val_jaccard_coef'],label='val_jaccard_coef')\nplt.plot(range(model_fitting.epoch[-1]+1),model_fitting.history['jaccard_coef'],label='trn_jaccard_coef')\nplt.title('Training Accuracy'); plt.xlabel('Epoch'); plt.ylabel('jaccard_coef');plt.legend(); \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:08:55.702646Z","iopub.execute_input":"2022-06-30T20:08:55.703091Z","iopub.status.idle":"2022-06-30T20:08:56.021838Z","shell.execute_reply.started":"2022-06-30T20:08:55.703055Z","shell.execute_reply":"2022-06-30T20:08:56.020832Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset(x_test, y_test)\ntest_dataloader = Dataloder(test_dataset, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:09:02.459621Z","iopub.execute_input":"2022-06-30T20:09:02.460506Z","iopub.status.idle":"2022-06-30T20:09:02.465945Z","shell.execute_reply.started":"2022-06-30T20:09:02.460467Z","shell.execute_reply":"2022-06-30T20:09:02.464845Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"## calculating the score\nScore= []\nfor i in tqdm(range(len(test_dataloader))):\n   pred_msk = model.predict(test_dataloader[i][0])\n   score = jaccard_coef(test_dataloader[i][1], pred_msk)\n   Score.append(score)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:10:04.868322Z","iopub.execute_input":"2022-06-30T20:10:04.869059Z","iopub.status.idle":"2022-06-30T20:11:54.200366Z","shell.execute_reply.started":"2022-06-30T20:10:04.869024Z","shell.execute_reply":"2022-06-30T20:11:54.199380Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"score = sum(Score)/len(test_dataloader)\nprint(\"The score obtained on the test data is: \", score.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:12:09.554300Z","iopub.execute_input":"2022-06-30T20:12:09.555050Z","iopub.status.idle":"2022-06-30T20:12:09.604986Z","shell.execute_reply.started":"2022-06-30T20:12:09.555012Z","shell.execute_reply":"2022-06-30T20:12:09.603912Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Performing Error Analysis","metadata":{}},{"cell_type":"code","source":"## total x and y values\ntotal_x = x_train + x_val + x_test\ntotal_y = y_train + y_val+ y_test","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:12:39.624052Z","iopub.execute_input":"2022-06-30T20:12:39.624649Z","iopub.status.idle":"2022-06-30T20:12:39.630560Z","shell.execute_reply.started":"2022-06-30T20:12:39.624611Z","shell.execute_reply":"2022-06-30T20:12:39.629405Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"total_dataset = Dataset(total_x, total_y)\ntotal_dataloader = Dataloder(total_dataset, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:12:41.620180Z","iopub.execute_input":"2022-06-30T20:12:41.620529Z","iopub.status.idle":"2022-06-30T20:12:41.625701Z","shell.execute_reply.started":"2022-06-30T20:12:41.620499Z","shell.execute_reply":"2022-06-30T20:12:41.624244Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"## to compute the similarity between two objects using jaccard coefficient\n\nScore= []\nvery_low_jaccard=[]\nmedium_jaccard= []\nvery_high_jaccard= []\n\nfor i in tqdm(range(len(total_dataloader))):\n\n   pred_msk = model.predict(total_dataloader[i][0])\n   score = jaccard_coef(total_dataloader[i][1], pred_msk)\n   \n   if score>0 and score <=0.20:\n      very_low_jaccard.append(i)\n\n   elif score>0.20 and score <=0.70:\n      medium_jaccard.append(i)\n   \n   elif score>0.70 and score <=1:\n      very_high_jaccard.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:12:44.031035Z","iopub.execute_input":"2022-06-30T20:12:44.031400Z","iopub.status.idle":"2022-06-30T20:25:40.554142Z","shell.execute_reply.started":"2022-06-30T20:12:44.031370Z","shell.execute_reply":"2022-06-30T20:25:40.553143Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"Very_low_jaccard_x = []\nMedium_jaccard_x = []\nVery_high_jaccard_x = []\n\nVery_low_jaccard_y = []\nMedium_jaccard_y = []\nVery_high_jaccard_y = []\n\nfor i in very_low_jaccard:\n   Very_low_jaccard_x.append(total_x[i])\nfor i in medium_jaccard:\n   Medium_jaccard_x.append(total_x[i])\nfor i in very_high_jaccard:\n   Very_high_jaccard_x.append(total_x[i])      \n\nfor i in very_low_jaccard:\n   Very_low_jaccard_y.append(total_y[i])\nfor i in medium_jaccard:\n   Medium_jaccard_y.append(total_y[i])\nfor i in very_high_jaccard:\n   Very_high_jaccard_y.append(total_y[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:05.350084Z","iopub.execute_input":"2022-06-30T20:26:05.350725Z","iopub.status.idle":"2022-06-30T20:26:05.368288Z","shell.execute_reply.started":"2022-06-30T20:26:05.350685Z","shell.execute_reply":"2022-06-30T20:26:05.367277Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"np.save(\"vljx\", Very_low_jaccard_x)\nnp.save(\"vljy\", Very_low_jaccard_y)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:09.598768Z","iopub.execute_input":"2022-06-30T20:26:09.599483Z","iopub.status.idle":"2022-06-30T20:26:09.619073Z","shell.execute_reply.started":"2022-06-30T20:26:09.599445Z","shell.execute_reply":"2022-06-30T20:26:09.618123Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"vljx = np.load(\"vljx.npy\")\nvljy = np.load(\"vljy.npy\")","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:11.152618Z","iopub.execute_input":"2022-06-30T20:26:11.152995Z","iopub.status.idle":"2022-06-30T20:26:11.160564Z","shell.execute_reply.started":"2022-06-30T20:26:11.152962Z","shell.execute_reply":"2022-06-30T20:26:11.159364Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"## converting a mask image into polygons\n    \ndef mask_to_polygons(mask, epsilon=5, min_area=1.):\n    \n    ##to detect objects in image\n    contours, hierarchy = cv2.findContours(((mask == 1) * 255).astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                       for cnt in contours]\n    if not contours:\n        return MultiPolygon()\n\n    cnt_children = defaultdict(list)\n    child_contours = set()\n    assert hierarchy.shape[0] == 1\n\n    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n        if parent_idx != -1:\n            child_contours.add(idx)\n            cnt_children[parent_idx].append(approx_contours[idx])\n\n    # creating actual polygons filtering it by area \n    all_polygons = []\n    for idx, cnt in enumerate(approx_contours):\n        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n            assert cnt.shape[1] == 1\n            poly = Polygon(\n                shell=cnt[:, 0, :],\n                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                       if cv2.contourArea(c) >= min_area])\n            all_polygons.append(poly)\n            \n    # approximating polygons might have created invalid ones, fix them\n    \n    all_polygons = MultiPolygon(all_polygons)\n    if not all_polygons.is_valid:\n        all_polygons = all_polygons.buffer(0)\n        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n        # need to keep it a Multi throughout\n        if all_polygons.type == 'Polygon':\n            all_polygons = MultiPolygon([all_polygons])\n    return all_polygons","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:15.074954Z","iopub.execute_input":"2022-06-30T20:26:15.075425Z","iopub.status.idle":"2022-06-30T20:26:15.094459Z","shell.execute_reply.started":"2022-06-30T20:26:15.075380Z","shell.execute_reply":"2022-06-30T20:26:15.093087Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"DF  = pd.DataFrame(columns=[\"image\", \"class\", \"poly\"])\n\nfor i in range(25):\n   abcd = np.load(vljy[i])\n   image, cl , ploy = [],[],[]\n  \n   for j in range(10):\n     ab = mask_to_polygons(abcd[:,:,j], epsilon=1)\n     image.append(i+1)\n     cl.append(j+1)\n     ploy.append(len(ab))\n     df = pd.DataFrame(list(zip(image, cl, ploy)), columns = ['image', 'class', 'poly'])\n\n   DF = pd.concat([DF,df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:18.479599Z","iopub.execute_input":"2022-06-30T20:26:18.479979Z","iopub.status.idle":"2022-06-30T20:26:19.187308Z","shell.execute_reply.started":"2022-06-30T20:26:18.479947Z","shell.execute_reply":"2022-06-30T20:26:19.186365Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"objects_per_image = DF.pivot(index='class', columns='image', values='poly')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:23.521090Z","iopub.execute_input":"2022-06-30T20:26:23.521659Z","iopub.status.idle":"2022-06-30T20:26:23.555648Z","shell.execute_reply.started":"2022-06-30T20:26:23.521625Z","shell.execute_reply":"2022-06-30T20:26:23.554465Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# OBSERVATIONS","metadata":{}},{"cell_type":"code","source":"print(\"minimum value in an image\",np.amin(np.load(vljx[0])))\nprint(\"maximum value in an image\",np.amax(np.load(vljx[0])))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:38.107301Z","iopub.execute_input":"2022-06-30T20:26:38.107675Z","iopub.status.idle":"2022-06-30T20:26:38.127637Z","shell.execute_reply.started":"2022-06-30T20:26:38.107642Z","shell.execute_reply":"2022-06-30T20:26:38.126595Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"threshold = 0.4\nSum = []\n\nfor i in tqdm(range(25)):\n   a = np.load(vljx[i])\n   im= []\n   for j in range(8):\n     im.append(np.count_nonzero(np.less(a[:,:,j], threshold))) \n   x = sum(im)\n   Sum.append(x)  \npercentage = (sum(Sum)/(160*160*8*25))*100","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:41.760709Z","iopub.execute_input":"2022-06-30T20:26:41.761206Z","iopub.status.idle":"2022-06-30T20:26:41.911280Z","shell.execute_reply.started":"2022-06-30T20:26:41.761168Z","shell.execute_reply":"2022-06-30T20:26:41.909200Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"## plotting the image\ndef plot_image(image_id):\n\n  m = np.load(vljx[image_id])\n  m = adjust_contrast(m)\n  img = np.zeros((m.shape[0],m.shape[1],3))\n  img[:,:,0] = m[:,:,4] #red\n  img[:,:,1] = m[:,:,2] #green\n  img[:,:,2] = m[:,:,1] #blue\n  #plt.figure(figsize=(7,7))\n  plt.imshow(img, interpolation='nearest')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:26:45.408591Z","iopub.execute_input":"2022-06-30T20:26:45.410940Z","iopub.status.idle":"2022-06-30T20:26:45.418190Z","shell.execute_reply.started":"2022-06-30T20:26:45.410902Z","shell.execute_reply":"2022-06-30T20:26:45.417276Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"## plotting the mask image\ndef plot_mask(mask_id):\n  m = np.load(vljy[i])\n  m = adjust_contrast(m)\n  img = np.zeros((m.shape[0],m.shape[1],3)) \n  img[:,:,0] = m[:,:,4] #red\n  img[:,:,1] = m[:,:,2] #green\n  img[:,:,2] = m[:,:,1] #blue\n  #plt.figure(figsize=(7,7))\n  plt.imshow(img, interpolation='nearest')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:27:08.314714Z","iopub.execute_input":"2022-06-30T20:27:08.315389Z","iopub.status.idle":"2022-06-30T20:27:08.322785Z","shell.execute_reply.started":"2022-06-30T20:27:08.315351Z","shell.execute_reply":"2022-06-30T20:27:08.321634Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"## printing the final output images\nfor i in range(10):\n   plot_image(i)\n   plot_mask(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T20:27:37.414032Z","iopub.execute_input":"2022-06-30T20:27:37.414522Z","iopub.status.idle":"2022-06-30T20:27:43.696733Z","shell.execute_reply.started":"2022-06-30T20:27:37.414476Z","shell.execute_reply":"2022-06-30T20:27:43.695806Z"},"trusted":true},"execution_count":59,"outputs":[]}]}